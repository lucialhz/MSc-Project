\subsection{Attestation of code integrity} \label{staticAttestationSolutions}

\subsubsection{SMART: Secure and Minimal Architecture for (Establishing a Dynamic) Root of Trust}
SMART \cite{For} provides a simple method of attesting the state of a user application through slight hardware alterations. As an input from the verifier it takes a nonce, start memory address and end memory address (as well as additional parameters for an optional start position of user application). The prover replies with a SHA-1 HMAC of the requested code space.

Important capabilities required by SMART are:
\begin{itemize}
	\item Secure HMAC key storage - this has not been directly addressed here however options are presented such as the key being hard-coded at production time (and never changed again) or by implementing a secure means of modifying by an authorized party, but not reading (as in the key can only be read by SMART). The second option was deferred to being future work.
	\item Secure HMAC key access - only SMART code on ROM can access the HMAC key. This is provided by registers only allowing access to the HMAC key while the program counter is located within SMART application space.
	\item It is not possible to enter or exit SMART instructions other than in the beginning or end. For example, if the program counter (\verb|pc|) is outside of SMART its previous location must also be outside of SMART (or the last instruction), and if the \verb|pc| is inside SMART its previous location must be at the start or also within SMART.
	\item Smart code is not editable, it is stored on ROM.
\end{itemize}

SMART was implemented on low-end microcontroller units (MCU)s such as MSP430 or AVR. After implementation it was realised that only the memory access controller needed to be modified, therefor making the solution possibly compatible with “black box” processors such as low-end ARM cores.

To critique the method - it uses SHA1 which is now outdated. It also could succumb to cold-boot attacks but the authors state that due to the typical MCU design where the processor and memory are a single package meaning that memory could not be accessed directly.

\subsubsection{VIPER: Verifying the Integrity of PERipherals’ Firmware}

VIPER \cite{Li2011} is a software only solution designed to provide attestation for peripherals’ firmware, where the host CPU queries peripherals. It uses combinations of checksums, hashes and time-frame based checks to ensure peripheral firmware is correct. The method consists of two parties: the verifier (host CPU) and the prover (peripheral). The verifier will have access to a ``checksum simulator'' which contains copies of correct firmware for each peripheral and is able to generate random numbers. The checksum simulator is first invoked, generating challenges (nonces) and the expected correct response from the prover by simulating the verification procedure on the correct peripheral firmware. This process is used to gain confidence that the verification\slash hash code is correct on the peripheral. The verifier then starts the process with the peripheral, requesting that the peripheral resets itself to a known-good state. Then the verifier starts a timer and sends the challenges, the peripheral then calculates the checksum over its checksum and hashing code and returns the result to the verifier. Finally the peripheral will compute the hash over the full contents of its memory, which is then sent to the verifier program for validation.

A significant proportion of this solution is focused on how latency needs to be taken into account for a live attestation protocol as the timing of the checksum calculations need to be precise enough to prevent the use of a proxy device to generate valid responses. This is also an important consideration when dealing with peripherals with different processing capabilities (consider a keyboard vs. a graphics card) as the response time will be significantly different. As this solution carries out attestation on multiple devices it is stated that it will attest high powered peripherals first, with slower peripherals subject to attestation in the later stages of the process. Additional methods are used to ensure use of a proxy is detectable such as increasing the proxy communications overhead and implementing continuous checksum computation. As much as the solution aims to address the latency and proxy system issue, time\slash delay-based protocols are still vulnerable to exploitation \cite{Castelluccia2009}, though it must be noted that the solution presented in \cite{Li2011} presents some promising protections against such attacks.

The paper \cite{Li2011} also provides an excellent description of the principles of designing a checksum function for the prover. These principles include using all available registers as part of the checksum calculation, the checksum should follow a pseudo-random pattern when reading from memory (preventing predictability for any attacker) and that the program counter (\verb|pc|) should be included in the calculation (if accessible). 

\subsubsection{Pioneer: Verifying Code Integrity and Enforcing Untampered Code Execution on Legacy Systems}

Pioneer \cite{Seshadri2007} is a software-only solution which works in a similar way to VIPER but is designed to attesting legacy systems. A checksum is calculated throughout the execution of the verifying (testing mechanism) code, the resulting execution time is compared to an expected execution time known to the verifier. This proves that the testing mechanism is correct. The testing mechanism then builds a hash of the target code. 

\subsubsection{SWATT: SoftWare-based ATTestation for Embedded Devices}

SWATT \cite{Seshadri2004} is a software-based solution which uses a random number generator to generate random memory addresses which are attested - this means an attacker cannot predict which regions they need to leave intact. They also use time measurement to ensure an attacker is not manipulating the results. This author questions whether that time-based checking is a reliable component, especially when attestation is taking place remotely, for example, over a network.
\ifnotesincluded
\furtherwork{Do I care?} 
\fi
This paper also references solutions which use secure coprocessors which are used during system initialisation to bootstrap trust, examples of these are TCG (Trusted Computing Group, formerly known as TCPA) and Next-Generation Secure Computing Base (NGSCB, formerly Palladium) which may be of interest at a later point as we will be able to see if they produce a useful output after startup has occurred.

\subsubsection{Software-Based Remote Code Attestation in Wireless Sensor Network}

AbuHMed at al \cite{AbuHmed2009} (again software-based) focusses on filling empty memory with predictable contents (such as ciphertext generated by the verifier) in an attempt to prevent an attacker from utilizing free space for malicious instructions.

\subsection{Dynamic attestation of code integrity} \label{dynamicAttestationSolutions}

\subsubsection{Remote Attestation to Dynamic System Properties: Towards Providing Complete System Integrity Evidence}

Kil et al \cite{Kil2009} aim to solve a different problem of attestation - that of dynamic attestation. It uses various different components to measure run-time statistics such as data invariants. They state that they aim for full coverage of the source code rather than all execution paths, the problem of achieving coverage is described as the equivalent to solving the halting problem. By being heavily interwoven with the Linux kernel they track all system calls. It heavily relies on the TPM to do the heavy lifting of signing attestation reports and isolating records of violations. This solution utilises a Merkel hash tree for use in authenticating input files for the proc file.

\subsection{Attacks on software-based static attestation} \label{attestationSolutionsAttacks}

\subsubsection{On the Difficulty of Software-Based Attestation of Embedded Devices}

This paper \cite{Castelluccia2009} that software-based attestation is a problematic solution. They attack SWATT \cite{Seshadri2004} by adding a hook into the attestation code which swaps out malicious code to data memory, as a result they recommend covering all memory in attestation processes (which they note would not be easy in embedded systems). They find that the time overhead relied upon by SWATT \cite{Seshadri2004} is imprecise and that their attacks fit within the tolerance. The paper also attacks solutions which fill empty memory with noise, as they found they could compress legitimate applications to make room for malicious ones.

\subsection{Conclusions on attestation} \label{attestationConclusion}

To provide attestation one usually requires a nonce and an area of memory to attest. The problem of offline attestation (audit) is that a previous good report could be cloned. To overcome this we should consider sequence numbers - where they need to be unique each time the process occurs, these would be stored alongside the HMAC prior to being encrypted. Another option could be using a time-stamp, however the time value would have to be strongly protected and secure in order to prevent an attacker from changing the time to the desired time when the attack is planned in order to create a ``good'' report. Chaining reports together may provide protection against this.

It seems that a large amount of the focus of the software-only mechanisms focus on proving the integrity of the verification software, which is a legitimate concern. Secure operating conditions or self attestation should  be able to provide for this.

A key learning from the solutions and the attack described is the importance of attesting all parts of memory.
