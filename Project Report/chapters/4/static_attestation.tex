\section{Comparison of solutions providing Static Attestation} \label{staticAttestationSolutions}

\subsection{Established Criteria}

We will compare each solution described in \ref{staticAttestationSolutions} using a set of defined properties. These properties are built using those described in \ref{comparisonOfCFISolutions} as a template and refined to suite the solutions for static attestation presented. The result of this comparison will be used to help define the static attestation phase of the proposed solution, and may also provide inspiration for the overall proposed solution.

\subsubsection*{Properties}
The properties which will be used for comparison are:
\begin{enumerate}[label=(\arabic*),noitemsep]
	\item Hardware-based: modification of hardware or additional hardware is required for the solution.			\item Software-based: the solution is created through the use of additional software.
	\item Successfully implemented: is the solution has been sucessfully implemented, this gives an indication on the legitimacy of the solution.
	\item Testing results: was the solution successful when defending against defined attacks.
	\item Instruction set architecture: what ISA the solution was initially designed for.
	\item Architecture-independent: will the solution be applicable to other architectures, as well as the architecture it was implemented and tested on.
\end{enumerate}

\subsection{Solutions Presented}

The following solutions have been presented for comparison through a combination of them being prominent work or by being referenced in control-flow attestations schemes which we have already analysed. We will provide a brief description of their methods and focus prior to presenting the results of a comparison of solutions in table~\ref{tab:staticAttestationComparisonRequirements}.

\subsubsection*{SMART: Secure and Minimal Architecture for (Establishing a Dynamic) Root of Trust}
SMART provides a simple method of attesting the state of a user application through slight hardware alterations \cite{For}. As an input from the verifier it takes a nonce, start memory address and end memory address (as well as additional parameters for an optional start position of user application). The prover replies with a SHA-1 HMAC of the requested code space.

Important capabilities required by SMART are:
\begin{itemize}
	\item Secure HMAC key storage - this has not been directly addressed here however options are presented such as the key being hard-coded at production time (and never changed again) or by implementing a secure means of modifying by an authorized party, but not reading (i.e. the key can only be read by SMART).
	\item Secure HMAC key access - only SMART code on ROM can access the HMAC key. This is provided by registers only allowing access to the HMAC key while the program counter is located within SMART application space.
	\item It is not possible to enter or exit SMART instructions other than in the beginning or end. For example, if the program counter (\verb|pc|) is outside of SMART its previous location must also be outside of SMART (or the last instruction), and if the \verb|pc| is inside SMART its previous location must be at the start or also within SMART.
	\item Smart code is not editable as it is stored on ROM.
\end{itemize}

SMART was implemented on low-end microcontroller units (MCUs) such as MSP430 or AVR. After implementation it was realised that only the memory access controller needed to be modified, therefore making the solution potentially compatible with ``black box'' processors such as low-end ARM cores.

A criticism of the method would be that it uses SHA1 which is now outdated. It may also succumb to cold-boot attacks however the authors state that due to the typical MCU design (where the processor and memory are a single package) memory could not be accessed directly so therefore is not vulnerable to this attack.

\subsubsection*{VIPER: Verifying the Integrity of PERipherals' Firmware}

VIPER is a software only solution designed to provide attestation for peripherals' firmware, where the host CPU queries peripherals \cite{Li2011}. It uses combinations of checksums, hashes and time-frame based checks to ensure peripheral firmware is correct. The method consists of two parties: the verifier (host CPU) and the prover (peripheral). The verifier will have access to a ``checksum simulator'' which contains copies of correct firmware for each peripheral and is able to generate random numbers. The checksum simulator is first invoked, generating challenges (nonces) and the expected correct response from the prover by simulating the verification procedure on the correct peripheral firmware. This process is used to gain confidence that the verification\slash hash code is correct on the peripheral. The verifier then starts the process with the peripheral, requesting that the peripheral resets itself to a known-good state. Then the verifier starts a timer and sends the challenges, the peripheral then calculates the checksum over its checksum and hashing code before returning the result to the verifier. Finally the peripheral will compute the hash over the full contents of its memory, which is then sent to the verifier program for validation.

A significant proportion of this solution is focused on how latency needs to be taken into account for a live attestation protocol as the timing of the checksum calculations need to be precise enough to prevent the use of a proxy device to generate valid responses. This is also an important consideration when dealing with peripherals with different processing capabilities (consider a keyboard vs. a graphics card) as the response time will be significantly different. As this solution carries out attestation on multiple devices it is stated that it will attest high powered peripherals first, with slower peripherals subject to attestation in the later stages of the process. Additional methods are used to ensure use of a proxy is detectable such as increasing the proxy communications overhead and implementing continuous checksum computation. As much as the solution aims to address the latency and proxy system issue, time\slash delay-based protocols are still vulnerable to exploitation \cite{Castelluccia2009}, though it must be noted that the solution presented in \cite{Li2011} presents some promising protections against such attacks.

The paper \cite{Li2011} also provides an excellent description of the principles of designing a checksum function for the prover. These principles include using all available registers as part of the checksum calculation, the checksum should follow a pseudo-random pattern when reading from memory (preventing predictability for any attacker) and that the program counter (\verb|pc|) should be included in the calculation (if accessible). 

\subsubsection*{Pioneer: Verifying Code Integrity and Enforcing Untampered Code Execution on Legacy Systems}

Pioneer is a software-only solution which works in a similar way to VIPER but is designed to attest remote legacy systems \cite{Seshadri2007}. A checksum is calculated throughout the execution of the verifying (testing mechanism) code, the resulting execution time is compared to an expected execution time known to the verifier. This proves that the testing mechanism is correct. The testing mechanism then builds a hash of the target code. 

This solution makes some major assumptions in order to ensure security. Some of these assumptions are easily attainable such as the verifier knowing the exact hardware configuration of the prover and platform having only a single CPU. While other assumptions seem to be less feasible such as the adversary not being able to generate a System Management Interrupt (SMI) on the prover, or assuming that the prover can only communicate with the attester during the attestation process (therefore preventing proxy attacks) through the use of a direct network connection or dedicated network configuration.

The paper provides a solid description of the design of the checksum and verification mechanisms, including design decisions based around stack layouts on the target architectures and how the \verb|pc| can be utilised.

\subsubsection*{SWATT: SoftWare-based ATTestation for Embedded Devices}

SWATT is a software-based solution which uses a random number generator (for example RC4 for 8-bit architectures, Helix for 32-bit architectures \cite{Ferguson2003}, or using bits from the output of a multi-word T-function for 16 and 32-bit architectures \cite{Klimov2004}) to generate random memory addresses which are attested \cite{Seshadri2004}. This means an attacker cannot predict which regions they need to leave intact. It is notable that the verification function is not the target of a separate checksum, but as the entire contents of memory are covered by the check it will be checked, just not to the same granularity as other solutions such as VIPER \cite{Li2011} or Pioneer \cite{Seshadri2007}. Like other static attestation methods, SWATT also uses time measurement to ensure an attacker is not manipulating the results. We question whether time-based checking is a reliable component, especially when attestation is taking place remotely, for example, over a network.
This paper also references solutions which use secure coprocessors which are used during system initialisation to bootstrap trust. Examples of these are TCG (Trusted Computing Group, formerly known as TCPA) and Next-Generation Secure Computing Base (NGSCB, formerly Palladium) which may be of interest at a later point as we will be able to see if they produce a useful output after start-up has occurred.

This paper notes that ``without secure hardware, a (potentially) compromised device cannot be trusted to verify itself correctly'' and therefore an external verifier is required. It also states that the solution described in \cite{Kennell2003} requires the use of a virtual memory subsystem and therefore will not work with many embedded systems as they have no support for virtual memory.

This solution requires that an attacker will not increase the size of memory on the prover device. 


\subsubsection*{Software-Based Remote Code Attestation in Wireless Sensor Network}

AbuHMed at al. \cite{AbuHmed2009} present a software-based solution which focuses on filling empty memory with predictable contents either prior to deployment or post-deployment in an attempt to prevent an attacker from utilizing free space for malicious instructions. An example method of filling empty memory is using generated ciphertext, utilising a key shared with the verifier as the seed. The verification of the memory is then performed in a similar pseudo-random manner as SWATT \cite{Seshadri2004}, but upgrading the pseudo-random number generating algorithm to RC5 (with the possibility of further upgrade to MISTY1, Rijndael or Skipjack). As the solution is not based around the timing of algorithms the authors find that it will be most useful in scenarios where multiple hops are required. They state that, through the use of pseudo-random memory traversal, proxy-based attacks are not possible. The use of predetermined noise to fill empty memory aids in this, however we observe that if a good device and its memory can be cloned, the original device could be vulnerable to a proxy-based attack.

\subsection{Discussion of Findings}

\input{chapters/4/static_attestation_table}
Table~\ref{tab:staticAttestationComparisonRequirements} shows how the solutions compare when taking some key properties into account. Most solutions are created only using software, this aids in ease of implementation and reducing cost. A large amount of the focus of the software-only mechanisms centres on proving the integrity of the verification software, which is a legitimate concern. Using a hardware-based mechanism assists in reducing this concern as it is assumed it cannot be modified. As can be seen, the choice of ISA is not important when performing static attestation, this is due to instructions not being the main focus (unlike control-flow attestation).

One notable assumption presumed by static-attestation solutions is that CPU clockspeed cannot be increased, or that CPU has not been changed. They tend to use optimised algorithms for computing checksums in order to make it easier to detect additional time added by attackers' attempts to circumvent the procedure.

This paper \cite{Castelluccia2009} finds that software-based attestation is a problematic solution. They attack SWATT \cite{Seshadri2004} by adding a hook into the attestation code which swaps out malicious code to data memory, and as a result they recommend covering all memory in attestation processes (which, they note, would not be easy in embedded systems). They find that the time overhead relied upon by SWATT \cite{Seshadri2004} is imprecise and that their attacks fit within the tolerance. The paper also attacks solutions which fill empty memory with noise, as they found they could compress legitimate applications to make room for malicious ones.

