\subsection{Attestation of code integrity} \label{staticAttestationSolutions}

\subsubsection{SMART: Secure and Minimal Architecture for (Establishing a Dynamic) Root of Trust}
SMART \cite{For} provides a simple method of attesting the state of a user application through slight hardware alterations. As an input from the verifier it takes a nonce, start memory address and end memory address (as well as additional parameters for an optional start position of user application). The prover replies with a SHA-1 HMAC of the requested code space.

Important capabilities required by SMART are:
\begin{itemize}
	\item Secure HMAC key storage - this has not been directly addressed here however options are presented such as the key being hard-coded at production time (and never changed again) or by implementing a secure means of modifying by an authorized party, but not reading (as in the key can only be read by SMART). The second option was deferred to being future work.
	\item Secure HMAC key access - only SMART code on ROM can access the HMAC key. This is provided by registers only allowing access to the HMAC key while the program counter is located within SMART application space.
	\item It is not possible to enter or exit SMART instructions other than in the beginning or end. For example, if the program counter (\verb|pc|) is outside of SMART its previous location must also be outside of SMART (or the last instruction), and if the \verb|pc| is inside SMART its previous location must be at the start or also within SMART.
	\item Smart code is not editable, it is stored on ROM.
\end{itemize}

SMART was implemented on low-end microcontroller units (MCU)s such as MSP430 or AVR. After implementation it was realised that only the memory access controller needed to be modified, therefor making the solution possibly compatible with “black box” processors such as low-end ARM cores.

To critique the method - it uses SHA1 which is now outdated. It also could succumb to cold-boot attacks but the authors state that due to the typical MCU design where the processor and memory are a single package meaning that memory could not be accessed directly.

\subsubsection{VIPER: Verifying the Integrity of PERipherals’ Firmware}

VIPER \cite{Li2011} is a software only solution designed to provide attestation for peripherals’ firmware, where the host CPU queries peripherals. It uses combinations of checksums, hashes and time-frame based checks to ensure peripheral firmware is correct. The method consists of two parties: the verifier (host CPU) and the prover (peripheral). The verifier will have access to a ``checksum simulator'' which contains copies of correct firmware for each peripheral and is able to generate random numbers. The checksum simulator is first invoked, generating challenges (nonces) and the expected correct response from the prover by simulating the verification procedure on the correct peripheral firmware. This process is used to gain confidence that the verification\slash hash code is correct on the peripheral. The verifier then starts the process with the peripheral, requesting that the peripheral resets itself to a known-good state. Then the verifier starts a timer and sends the challenges, the peripheral then calculates the checksum over its checksum and hashing code and returns the result to the verifier. Finally the peripheral will compute the hash over the full contents of its memory, which is then sent to the verifier program for validation.

A significant proportion of this solution is focused on how latency needs to be taken into account for a live attestation protocol as the timing of the checksum calculations need to be precise enough to prevent the use of a proxy device to generate valid responses. This is also an important consideration when dealing with peripherals with different processing capabilities (consider a keyboard vs. a graphics card) as the response time will be significantly different. As this solution carries out attestation on multiple devices it is stated that it will attest high powered peripherals first, with slower peripherals subject to attestation in the later stages of the process. Additional methods are used to ensure use of a proxy is detectable such as increasing the proxy communications overhead and implementing continuous checksum computation. As much as the solution aims to address the latency and proxy system issue, time\slash delay-based protocols are still vulnerable to exploitation \cite{Castelluccia2009}, though it must be noted that the solution presented in \cite{Li2011} presents some promising protections against such attacks.

The paper \cite{Li2011} also provides an excellent description of the principles of designing a checksum function for the prover. These principles include using all available registers as part of the checksum calculation, the checksum should follow a pseudo-random pattern when reading from memory (preventing predictability for any attacker) and that the program counter (\verb|pc|) should be included in the calculation (if accessible). 

\subsubsection{Pioneer: Verifying Code Integrity and Enforcing Untampered Code Execution on Legacy Systems}

Pioneer \cite{Seshadri2007} is a software-only solution which works in a similar way to VIPER but is designed to attest remote legacy systems. A checksum is calculated throughout the execution of the verifying (testing mechanism) code, the resulting execution time is compared to an expected execution time known to the verifier. This proves that the testing mechanism is correct. The testing mechanism then builds a hash of the target code. 

This solution makes some major assumptions in order to ensure security, some of these are easily attainable such as the verifier knowing the exact hardware configuration of the prover and platform having only a single CPU. Other assumptions seem to be less feasible such as the adversary not being able to generate a System Management Interrupt (SMI) on the prover, or assuming that the prover can only communicate with the attester during the attestation process (therefore preventing proxy attacks) through the use of a direct network connection or dedicated network configuration.

The paper provides a solid description of the design of the checksum and verification mechanisms, including design decisions based around stack layouts on the target architectures and how the \verb|pc| can be utilised.

\subsubsection{SWATT: SoftWare-based ATTestation for Embedded Devices}

SWATT \cite{Seshadri2004} is a software-based solution which uses a random number generator (for example RC4 for 8-bit architectures, Helix for 32-bit architectures \cite{Ferguson2003}, or using bits from the output of a multi-word T-function for 16 and 32-bit architectures \cite{Klimov2004}) to generate random memory addresses which are attested - this means an attacker cannot predict which regions they need to leave intact. It is notable that the verification function is not the target of a separate checksum, but as the entire contents of memory are covered by the check it will be checked, just not to the same granularity as other solutions such as VIPER \cite{Li2011} or Pioneer \cite{Seshadri2007}. Like other static attestation methods, SWATT also uses time measurement to ensure an attacker is not manipulating the results. This author questions whether that time-based checking is a reliable component, especially when attestation is taking place remotely, for example, over a network.
This paper also references solutions which use secure coprocessors which are used during system initialisation to bootstrap trust, examples of these are TCG (Trusted Computing Group, formerly known as TCPA) and Next-Generation Secure Computing Base (NGSCB, formerly Palladium) which may be of interest at a later point as we will be able to see if they produce a useful output after start-up has occurred.

This paper notes that ``without secure hardware, a (potentially) compromised device cannot be trusted to verify itself correctly'' and therefore an external verifier is required. It also states that the solution described in \cite{Kennell2003} requires the use of a virtual memory subsystem and therefore will not work with many embedded systems as they have no support for virtual memory.

This solution requires that an attacker will not increase the size of memory on the prover device. 


\subsubsection{Software-Based Remote Code Attestation in Wireless Sensor Network}

AbuHMed at al \cite{AbuHmed2009} present a software-based solution which focus on filling empty memory with predictable contents either prior to deployment or post-deployment in an attempt to prevent an attacker from utilizing free space for malicious instructions.. An example method of generation is ciphertext generated using a key shared with the verifier as the seed). The verification of the memory is then performed in a similar pseudo-random manner as SWATT \cite{Seshadri2004}, but upgrading the pseudo-randon number generating algorithm to RC5 (with the possibility of further upgrade to MISTY1, Rijndael or Skipjack). As the solution is not based around the timing of algorithms the authors find that it will be most useful in scenarios where multiple hops are required. They state that, through the use of pseudo-random memory traversal, proxy-based attacks are not possible. The use of predetermined noise to fill empty memory aids in this, however we observe that if a good device and its memory can be cloned, the original device could be vulnerable to a proxy-based attack.

\subsection{Dynamic attestation of code integrity} \label{dynamicAttestationSolutions}

\subsubsection{Remote Attestation to Dynamic System Properties: Towards Providing Complete System Integrity Evidence}

Kil et al \cite{Kil2009} aim to solve a different problem of attestation - that of dynamic attestation. It uses various different components to measure run-time statistics such as data invariants. They state that they aim for full coverage of the source code rather than all execution paths, the problem of achieving coverage is described as the equivalent to solving the halting problem. By being heavily interwoven with the Linux kernel they track all system calls. It heavily relies on the TPM to do the heavy lifting of signing attestation reports and isolating records of violations. This solution utilises a Merkel hash tree for use in authenticating input files for the proc file.

\subsection{Attacks on software-based static attestation} \label{attestationSolutionsAttacks}

\subsubsection{On the Difficulty of Software-Based Attestation of Embedded Devices}

This paper \cite{Castelluccia2009} that software-based attestation is a problematic solution. They attack SWATT \cite{Seshadri2004} by adding a hook into the attestation code which swaps out malicious code to data memory, as a result they recommend covering all memory in attestation processes (which they note would not be easy in embedded systems). They find that the time overhead relied upon by SWATT \cite{Seshadri2004} is imprecise and that their attacks fit within the tolerance. The paper also attacks solutions which fill empty memory with noise, as they found they could compress legitimate applications to make room for malicious ones.

\subsection{Conclusions on attestation} \label{attestationConclusion}

To provide attestation one usually requires a nonce and an area of memory to attest. The problem of offline attestation (audit) is that a previous good report could be cloned. To overcome this we should consider sequence numbers - where they need to be unique each time the process occurs, these would be stored alongside the HMAC prior to being encrypted. Another option could be using a time-stamp, however the time value would have to be strongly protected and secure in order to prevent an attacker from changing the time to the desired time when the attack is planned in order to create a ``good'' report. Chaining reports together may provide protection against this.

It seems that a large amount of the focus of the software-only mechanisms focus on proving the integrity of the verification software, which is a legitimate concern. Secure operating conditions or self attestation should  be able to provide for this.

A key learning from the solutions and the attack described is the importance of attesting all parts of memory.

Proxy attacks should not be a problem for self attestation if attestation is only performed through internal APIs.

One major assumption presumed by all is that CPU clockspeed cannot be increased, or that CPU has not been changed. They all also use optimised algorithms for computing checksums in order to make it easier to detect additional time added by attackers' attempts to circumvent the procedure.